from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
import time
import json
import re
import logging

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# Firebase MCP ê·œì¹™ import
try:
    from ..firebase_mcp_rules import (
        validate_mcp_call, handle_mcp_error,
        validate_schedule_memo, validate_response, log_operation
    )
    MCP_RULES_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Firebase MCP ê·œì¹™ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    MCP_RULES_AVAILABLE = False
    
    # í´ë°± í•¨ìˆ˜ë“¤ ì •ì˜
    def validate_mcp_call(*args, **kwargs): return True
    def handle_mcp_error(error, context=""): return str(error)
    def validate_schedule_memo(*args, **kwargs): return True
    def validate_response(response): return response is not None
    def log_operation(*args, **kwargs): pass

# Firebase ë„êµ¬ import
try:
    from ..tools.firebase_tools import query_any_collection
    FIREBASE_TOOLS_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Firebase ë„êµ¬ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    FIREBASE_TOOLS_AVAILABLE = False
    
    # í´ë°± í•¨ìˆ˜
    def query_any_collection(collection_name: str, conditions: list = None) -> dict:
        return {"status": "error", "message": "Firebase ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

# Firebase í´ë¼ì´ì–¸íŠ¸ import
try:
    from ..client.firebase_client import firebase_client
    FIREBASE_CLIENT_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Firebase í´ë¼ì´ì–¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    FIREBASE_CLIENT_AVAILABLE = False
    
    # í´ë°± í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤
    class MockFirebaseClient:
        def update_document(self, doc_path: str, data: dict) -> dict:
            return {"status": "error", "message": "Firebase í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    firebase_client = MockFirebaseClient()

# ==============================================================================
# ğŸ”§ ê³µí†µ í—¬í¼ í•¨ìˆ˜ë“¤
# ==============================================================================

# ìŠ¤ì¼€ì¤„ ì»¬ë ‰ì…˜ íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬ (ì£¼ì†Œê°€ ì•„ë‹Œ ì„ íƒ ê°€ëŠ¥í•œ í•­ëª©ë“¤)
SPECIAL_SCHEDULE_CATEGORIES = {
    "ê°œì¸ ì¼ì •",
    "í•˜ìë³´ìˆ˜", 
    "ê³ ê° ìƒë‹´"
}

def _parse_date_string(date_str: str) -> str:
    """ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ì„ YYYY-MM-DDë¡œ ë³€í™˜
    
    Args:
        date_str: ì…ë ¥ ë‚ ì§œ ë¬¸ìì—´ ("6ì›” 15ì¼", "6/15", "2025-06-15" ë“±)
        
    Returns:
        str: YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´
    """
    current_year = datetime.now().year
    
    # ì´ë¯¸ YYYY-MM-DD í˜•ì‹ì¸ ê²½ìš°
    if re.match(r'^\d{4}-\d{2}-\d{2}$', date_str):
        return date_str
    
    # "6ì›” 15ì¼" í˜•ì‹
    month_day_match = re.match(r'(\d{1,2})ì›”\s*(\d{1,2})ì¼', date_str)
    if month_day_match:
        month = int(month_day_match.group(1))
        day = int(month_day_match.group(2))
        return f"{current_year}-{month:02d}-{day:02d}"
    
    # "6/15" í˜•ì‹
    slash_match = re.match(r'(\d{1,2})/(\d{1,2})$', date_str)
    if slash_match:
        month = int(slash_match.group(1))
        day = int(slash_match.group(2))
        return f"{current_year}-{month:02d}-{day:02d}"
    
    # "15ì¼" í˜•ì‹ (í˜„ì¬ ì›” ê¸°ì¤€)
    day_only_match = re.match(r'(\d{1,2})ì¼$', date_str)
    if day_only_match:
        current_month = datetime.now().month
        day = int(day_only_match.group(1))
        return f"{current_year}-{current_month:02d}-{day:02d}"
    
    # íŒŒì‹± ì‹¤íŒ¨ì‹œ ì˜¤ëŠ˜ ë‚ ì§œ ë°˜í™˜
    logger.warning(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_str}, ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©")
    return datetime.now().strftime("%Y-%m-%d")

def _find_schedule_document(address: str) -> Tuple[bool, Optional[str], Optional[dict]]:
    """addressë¡œ schedules ë¬¸ì„œ ì°¾ê¸°
    
    Args:
        address: ì°¾ì„ ì£¼ì†Œ ë˜ëŠ” íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬ ("ê°œì¸ ì¼ì •", "í•˜ìë³´ìˆ˜", "ê³ ê° ìƒë‹´")
        
    Returns:
        tuple: (ì°¾ìŒ ì—¬ë¶€, ë¬¸ì„œ ID, ë¬¸ì„œ ë°ì´í„°)
    """
    try:
        # MCP ê·œì¹™ ê²€ì¦
        if not validate_mcp_call("query_any_collection", collection="schedules", address=address):
            return False, None, None
        
        # schedules ì»¬ë ‰ì…˜ ì¡°íšŒ
        result = query_any_collection("schedules")
        
        if not validate_response(result) or result.get("status") != "success":
            logger.error(f"ìŠ¤ì¼€ì¤„ ì»¬ë ‰ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {result}")
            return False, None, None
        
        documents = result.get("data", {}).get("documents", [])
        
        # address í•„ë“œë¡œ ë¬¸ì„œ ê²€ìƒ‰ (ì‹¤ì œ ì£¼ì†Œ ë˜ëŠ” íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬)
        for doc in documents:
            doc_data = doc.get("data", {})
            if doc_data.get("address") == address:
                doc_id = doc.get("id")
                log_operation("find_schedule_document", "success", {"address": address, "doc_id": doc_id, "type": "found"})
                return True, doc_id, doc_data
        
        # íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬ì¸ ê²½ìš° ìë™ ìƒì„± ê°€ëŠ¥í•˜ë‹¤ê³  ì•Œë¦¼
        if address in SPECIAL_SCHEDULE_CATEGORIES:
            log_operation("find_schedule_document", "special_category", {"address": address, "type": "special"})
            return False, None, {"is_special_category": True}
        
        log_operation("find_schedule_document", "not_found", {"address": address, "type": "not_found"})
        return False, None, None
        
    except Exception as e:
        error_msg = handle_mcp_error(e, f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ (address: {address})")
        logger.error(error_msg)
        return False, None, None

def _update_events_json(doc_id: str, updated_events: dict) -> dict:
    """eventsJson í•„ë“œë¥¼ ì•ˆì „í•˜ê²Œ ì—…ë°ì´íŠ¸
    
    Args:
        doc_id: ì—…ë°ì´íŠ¸í•  ë¬¸ì„œ ID
        updated_events: ì—…ë°ì´íŠ¸í•  ì´ë²¤íŠ¸ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        dict: ì—…ë°ì´íŠ¸ ê²°ê³¼
    """
    try:
        # MCP ê·œì¹™ ê²€ì¦
        if not validate_mcp_call("update_document", doc_id=doc_id, events=updated_events):
            return {"status": "error", "message": "MCP ê·œì¹™ ê²€ì¦ ì‹¤íŒ¨"}
        
        # JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        events_json_str = json.dumps(updated_events, ensure_ascii=False)
        
        # ë¬¸ì„œ ì—…ë°ì´íŠ¸
        doc_path = f"schedules/{doc_id}"
        update_data = {
            "eventsJson": events_json_str,
            "updatedAt": datetime.now().isoformat()
        }
        
        result = firebase_client.update_document(doc_path, update_data)
        
        if validate_response(result):
            log_operation("update_events_json", "success", {"doc_id": doc_id, "events_count": len(updated_events)})
            return {"status": "success", "data": result}
        else:
            return {"status": "error", "message": "ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨"}
            
    except Exception as e:
        error_msg = handle_mcp_error(e, f"eventsJson ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ (doc_id: {doc_id})")
        logger.error(error_msg)
        return {"status": "error", "message": error_msg}

# ==============================================================================
# ğŸ¯ í•µì‹¬ ê¸°ëŠ¥ 5ê°€ì§€
# ==============================================================================

def register_new_schedule(address: str, date: str, work_type: str, memo: str = "") -> dict:
    """ìƒˆë¡œìš´ ìŠ¤ì¼€ì¤„ì„ ë“±ë¡í•©ë‹ˆë‹¤.
    
    Args:
        address: í˜„ì¥ ì£¼ì†Œ ë˜ëŠ” íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬ ("ê°œì¸ ì¼ì •", "í•˜ìë³´ìˆ˜", "ê³ ê° ìƒë‹´")
        date: ìŠ¤ì¼€ì¤„ ë‚ ì§œ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
        work_type: ì‘ì—… ìœ í˜•
        memo: ì¶”ê°€ ë©”ëª¨ (ì„ íƒì‚¬í•­)
        
    Returns:
        dict: ë“±ë¡ ê²°ê³¼
    """
    try:
        # ì…ë ¥ ê²€ì¦
        if not address or not date:
            return {"status": "error", "message": "âŒ ì£¼ì†Œì™€ ë‚ ì§œëŠ” í•„ìˆ˜ ì…ë ¥ì‚¬í•­ì…ë‹ˆë‹¤.", "error_type": "invalid_input"}
        
        # ë‚ ì§œ íŒŒì‹±
        parsed_date = _parse_date_string(date)
        
        # ìŠ¤ì¼€ì¤„ ë©”ëª¨ ê²€ì¦
        final_memo = memo or work_type
        if not validate_schedule_memo(final_memo):
            return {"status": "error", "message": "âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ë©”ëª¨ ë‚´ìš©ì…ë‹ˆë‹¤.", "error_type": "invalid_memo"}
        
        # ë¬¸ì„œ ê²€ìƒ‰
        found, doc_id, doc_data = _find_schedule_document(address)
        
        if not found:
            # íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬ì¸ ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€ ë³€ê²½
            if doc_data and doc_data.get("is_special_category"):
                return {
                    "status": "error",
                    "message": f"âŒ '{address}' ì¹´í…Œê³ ë¦¬ì˜ ìŠ¤ì¼€ì¤„ ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                    "error_type": "category_not_found",
                    "available_categories": list(SPECIAL_SCHEDULE_CATEGORIES)
                }
            else:
                return {
                    "status": "error", 
                    "message": f"âŒ '{address}' ì£¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì£¼ì†Œë¥¼ ë¨¼ì € ë“±ë¡í•´ì£¼ì„¸ìš”.",
                    "error_type": "address_not_found",
                    "hint": f"íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´: {', '.join(SPECIAL_SCHEDULE_CATEGORIES)}"
                }
        
        # ê¸°ì¡´ eventsJson íŒŒì‹±
        events_json_str = doc_data.get("eventsJson", "{}")
        try:
            existing_events = json.loads(events_json_str)
        except json.JSONDecodeError:
            existing_events = {}
        
        # ìƒˆ ì´ë²¤íŠ¸ ìƒì„±
        event_key = f"{parsed_date}_{int(time.time() * 1000)}"
        event_data = {
            "title": "",
            "status": "scheduled",
            "memo": final_memo
        }
        
        # ì´ë²¤íŠ¸ ì¶”ê°€
        existing_events[event_key] = event_data
        
        # ë¬¸ì„œ ì—…ë°ì´íŠ¸
        update_result = _update_events_json(doc_id, existing_events)
        
        if update_result.get("status") == "success":
            return {
                "status": "success",
                "message": f"âœ… {address}ì— {parsed_date} ìŠ¤ì¼€ì¤„ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "data": {
                    "address": address,
                    "date": parsed_date,
                    "work_type": work_type,
                    "memo": final_memo,
                    "action": "registered"
                }
            }
        else:
            return {
                "status": "error",
                "message": f"âŒ ìŠ¤ì¼€ì¤„ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {update_result.get('message')}",
                "error_type": "update_failed"
            }
            
    except Exception as e:
        error_msg = handle_mcp_error(e, f"ìŠ¤ì¼€ì¤„ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ (address: {address}, date: {date})")
        logger.error(error_msg)
        return {"status": "error", "message": f"âŒ ìŠ¤ì¼€ì¤„ ë“±ë¡ ì‹¤íŒ¨: {error_msg}", "error_type": "system_error"}

def update_existing_schedule(address: str, date: str, new_memo: str, new_work_type: str = "") -> dict:
    """ê¸°ì¡´ ìŠ¤ì¼€ì¤„ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.
    
    Args:
        address: í˜„ì¥ ì£¼ì†Œ ë˜ëŠ” íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬ ("ê°œì¸ ì¼ì •", "í•˜ìë³´ìˆ˜", "ê³ ê° ìƒë‹´")
        date: ìˆ˜ì •í•  ìŠ¤ì¼€ì¤„ ë‚ ì§œ
        new_memo: ìƒˆë¡œìš´ ë©”ëª¨ ë‚´ìš©
        new_work_type: ìƒˆë¡œìš´ ì‘ì—… ìœ í˜• (ì„ íƒì‚¬í•­)
        
    Returns:
        dict: ìˆ˜ì • ê²°ê³¼
    """
    try:
        # ì…ë ¥ ê²€ì¦
        if not address or not date or not new_memo:
            return {"status": "error", "message": "âŒ ì£¼ì†Œ, ë‚ ì§œ, ìƒˆ ë©”ëª¨ëŠ” í•„ìˆ˜ ì…ë ¥ì‚¬í•­ì…ë‹ˆë‹¤.", "error_type": "invalid_input"}
        
        # ë‚ ì§œ íŒŒì‹±
        parsed_date = _parse_date_string(date)
        
        # ë©”ëª¨ ê²€ì¦
        if not validate_schedule_memo(new_memo):
            return {"status": "error", "message": "âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ë©”ëª¨ ë‚´ìš©ì…ë‹ˆë‹¤.", "error_type": "invalid_memo"}
        
        # ë¬¸ì„œ ê²€ìƒ‰
        found, doc_id, doc_data = _find_schedule_document(address)
        
        if not found:
            # íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬ì¸ ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€ ë³€ê²½
            if doc_data and doc_data.get("is_special_category"):
                return {
                    "status": "error",
                    "message": f"âŒ '{address}' ì¹´í…Œê³ ë¦¬ì˜ ìŠ¤ì¼€ì¤„ ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                    "error_type": "category_not_found",
                    "available_categories": list(SPECIAL_SCHEDULE_CATEGORIES)
                }
            else:
                return {
                    "status": "error",
                    "message": f"âŒ '{address}' ì£¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "error_type": "address_not_found",
                    "hint": f"íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬: {', '.join(SPECIAL_SCHEDULE_CATEGORIES)}"
                }
        
        # ê¸°ì¡´ eventsJson íŒŒì‹±
        events_json_str = doc_data.get("eventsJson", "{}")
        try:
            existing_events = json.loads(events_json_str)
        except json.JSONDecodeError:
            existing_events = {}
        
        # í•´ë‹¹ ë‚ ì§œì˜ ì´ë²¤íŠ¸ ì°¾ê¸°
        matching_keys = [key for key in existing_events.keys() if key.startswith(f"{parsed_date}_")]
        
        if not matching_keys:
            return {
                "status": "error",
                "message": f"âŒ {parsed_date}ì— ë“±ë¡ëœ ìŠ¤ì¼€ì¤„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "error_type": "date_not_found"
            }
        
        # ì²« ë²ˆì§¸ ë§¤ì¹­ë˜ëŠ” ì´ë²¤íŠ¸ ìˆ˜ì • (ë³´í†µ í•˜ë£¨ì— í•˜ë‚˜ì˜ ì£¼ìš” ì¼ì •)
        event_key = matching_keys[0]
        existing_events[event_key]["memo"] = new_memo
        
        # ì‘ì—… ìœ í˜•ì´ ì œê³µëœ ê²½ìš° ì—…ë°ì´íŠ¸
        if new_work_type:
            # title í•„ë“œê°€ ìˆë‹¤ë©´ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ êµ¬ì¡° ìœ ì§€)
            if "title" in existing_events[event_key]:
                existing_events[event_key]["title"] = new_work_type
        
        # ë¬¸ì„œ ì—…ë°ì´íŠ¸
        update_result = _update_events_json(doc_id, existing_events)
        
        if update_result.get("status") == "success":
            return {
                "status": "success",
                "message": f"âœ… {address}ì˜ {parsed_date} ìŠ¤ì¼€ì¤„ì´ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "data": {
                    "address": address,
                    "date": parsed_date,
                    "new_memo": new_memo,
                    "new_work_type": new_work_type,
                    "action": "updated"
                }
            }
        else:
            return {
                "status": "error",
                "message": f"âŒ ìŠ¤ì¼€ì¤„ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {update_result.get('message')}",
                "error_type": "update_failed"
            }
            
    except Exception as e:
        error_msg = handle_mcp_error(e, f"ìŠ¤ì¼€ì¤„ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ (address: {address}, date: {date})")
        logger.error(error_msg)
        return {"status": "error", "message": f"âŒ ìŠ¤ì¼€ì¤„ ìˆ˜ì • ì‹¤íŒ¨: {error_msg}", "error_type": "system_error"}

def delete_schedule_record(address: str, date: str) -> dict:
    """íŠ¹ì • ë‚ ì§œì˜ ìŠ¤ì¼€ì¤„ì„ ì‚­ì œí•©ë‹ˆë‹¤.
    
    Args:
        address: í˜„ì¥ ì£¼ì†Œ ë˜ëŠ” íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬ ("ê°œì¸ ì¼ì •", "í•˜ìë³´ìˆ˜", "ê³ ê° ìƒë‹´")
        date: ì‚­ì œí•  ìŠ¤ì¼€ì¤„ ë‚ ì§œ
        
    Returns:
        dict: ì‚­ì œ ê²°ê³¼
    """
    try:
        # ì…ë ¥ ê²€ì¦
        if not address or not date:
            return {"status": "error", "message": "âŒ ì£¼ì†Œì™€ ë‚ ì§œëŠ” í•„ìˆ˜ ì…ë ¥ì‚¬í•­ì…ë‹ˆë‹¤.", "error_type": "invalid_input"}
        
        # ë‚ ì§œ íŒŒì‹±
        parsed_date = _parse_date_string(date)
        
        # ë¬¸ì„œ ê²€ìƒ‰
        found, doc_id, doc_data = _find_schedule_document(address)
        
        if not found:
            # íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬ì¸ ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€ ë³€ê²½
            if doc_data and doc_data.get("is_special_category"):
                return {
                    "status": "error",
                    "message": f"âŒ '{address}' ì¹´í…Œê³ ë¦¬ì˜ ìŠ¤ì¼€ì¤„ ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                    "error_type": "category_not_found",
                    "available_categories": list(SPECIAL_SCHEDULE_CATEGORIES)
                }
            else:
                return {
                    "status": "error",
                    "message": f"âŒ '{address}' ì£¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "error_type": "address_not_found",
                    "hint": f"íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬: {', '.join(SPECIAL_SCHEDULE_CATEGORIES)}"
                }
        
        # ê¸°ì¡´ eventsJson íŒŒì‹±
        events_json_str = doc_data.get("eventsJson", "{}")
        try:
            existing_events = json.loads(events_json_str)
        except json.JSONDecodeError:
            existing_events = {}
        
        # í•´ë‹¹ ë‚ ì§œì˜ ì´ë²¤íŠ¸ ì°¾ê¸° ë° ì‚­ì œ
        keys_to_delete = [key for key in existing_events.keys() if key.startswith(f"{parsed_date}_")]
        
        if not keys_to_delete:
            return {
                "status": "error",
                "message": f"âŒ {parsed_date}ì— ì‚­ì œí•  ìŠ¤ì¼€ì¤„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "error_type": "date_not_found"
            }
        
        # ì´ë²¤íŠ¸ ì‚­ì œ
        deleted_count = 0
        for key in keys_to_delete:
            del existing_events[key]
            deleted_count += 1
        
        # ë¬¸ì„œ ì—…ë°ì´íŠ¸
        update_result = _update_events_json(doc_id, existing_events)
        
        if update_result.get("status") == "success":
            return {
                "status": "success",
                "message": f"âœ… {address}ì˜ {parsed_date} ìŠ¤ì¼€ì¤„ {deleted_count}ê°œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "data": {
                    "address": address,
                    "date": parsed_date,
                    "deleted_count": deleted_count,
                    "action": "deleted"
                }
            }
        else:
            return {
                "status": "error",
                "message": f"âŒ ìŠ¤ì¼€ì¤„ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {update_result.get('message')}",
                "error_type": "update_failed"
            }
            
    except Exception as e:
        error_msg = handle_mcp_error(e, f"ìŠ¤ì¼€ì¤„ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ (address: {address}, date: {date})")
        logger.error(error_msg)
        return {"status": "error", "message": f"âŒ ìŠ¤ì¼€ì¤„ ì‚­ì œ ì‹¤íŒ¨: {error_msg}", "error_type": "system_error"}

def list_schedules_by_date(date: str) -> dict:
    """íŠ¹ì • ë‚ ì§œì˜ ëª¨ë“  ìŠ¤ì¼€ì¤„ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Args:
        date: ì¡°íšŒí•  ë‚ ì§œ
        
    Returns:
        dict: ì¡°íšŒ ê²°ê³¼
    """
    try:
        # ì…ë ¥ ê²€ì¦
        if not date:
            return {"status": "error", "message": "âŒ ë‚ ì§œëŠ” í•„ìˆ˜ ì…ë ¥ì‚¬í•­ì…ë‹ˆë‹¤.", "error_type": "invalid_input"}
        
        # ë‚ ì§œ íŒŒì‹±
        parsed_date = _parse_date_string(date)
        
        # MCP ê·œì¹™ ê²€ì¦
        if not validate_mcp_call("query_any_collection", collection="schedules", date=parsed_date):
            return {"status": "error", "message": "âŒ MCP ê·œì¹™ ê²€ì¦ ì‹¤íŒ¨", "error_type": "mcp_validation_failed"}
        
        # ëª¨ë“  schedules ë¬¸ì„œ ì¡°íšŒ
        result = query_any_collection("schedules")
        
        if not validate_response(result) or result.get("status") != "success":
            return {"status": "error", "message": "âŒ ìŠ¤ì¼€ì¤„ ì»¬ë ‰ì…˜ ì¡°íšŒ ì‹¤íŒ¨", "error_type": "query_failed"}
        
        documents = result.get("data", {}).get("documents", [])
        schedules = []
        
        # ê° ë¬¸ì„œì—ì„œ í•´ë‹¹ ë‚ ì§œì˜ ì´ë²¤íŠ¸ ê²€ìƒ‰
        for doc in documents:
            doc_data = doc.get("data", {})
            address = doc_data.get("address", "ì•Œ ìˆ˜ ì—†ëŠ” ì£¼ì†Œ")
            events_json_str = doc_data.get("eventsJson", "{}")
            
            try:
                events = json.loads(events_json_str)
                
                # í•´ë‹¹ ë‚ ì§œì˜ ì´ë²¤íŠ¸ ì°¾ê¸°
                for event_key, event_data in events.items():
                    if event_key.startswith(f"{parsed_date}_"):
                        schedule_info = {
                            "address": address,
                            "date": parsed_date,
                            "memo": event_data.get("memo", ""),
                            "status": event_data.get("status", "unknown"),
                            "title": event_data.get("title", ""),
                            "event_key": event_key
                        }
                        schedules.append(schedule_info)
                        
            except json.JSONDecodeError:
                logger.warning(f"eventsJson íŒŒì‹± ì‹¤íŒ¨ (address: {address})")
                continue
        
        # ê²°ê³¼ ì •ë ¬ (ì£¼ì†Œë³„)
        schedules.sort(key=lambda x: x["address"])
        
        log_operation("list_schedules_by_date", "success", {"date": parsed_date, "count": len(schedules)})
        
        return {
            "status": "success",
            "message": f"âœ… {parsed_date}ì˜ ìŠ¤ì¼€ì¤„ {len(schedules)}ê°œë¥¼ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.",
            "data": {
                "date": parsed_date,
                "schedules": schedules,
                "count": len(schedules),
                "action": "listed"
            }
        }
        
    except Exception as e:
        error_msg = handle_mcp_error(e, f"ìŠ¤ì¼€ì¤„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ (date: {date})")
        logger.error(error_msg)
        return {"status": "error", "message": f"âŒ ìŠ¤ì¼€ì¤„ ì¡°íšŒ ì‹¤íŒ¨: {error_msg}", "error_type": "system_error"}

def list_schedules_by_address(address: str) -> dict:
    """íŠ¹ì • ì£¼ì†Œ/ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  ìŠ¤ì¼€ì¤„ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Args:
        address: ì¡°íšŒí•  ì£¼ì†Œ ë˜ëŠ” íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬ ("ê°œì¸ ì¼ì •", "í•˜ìë³´ìˆ˜", "ê³ ê° ìƒë‹´")
        
    Returns:
        dict: ì¡°íšŒ ê²°ê³¼
    """
    try:
        # ì…ë ¥ ê²€ì¦
        if not address:
            return {"status": "error", "message": "âŒ ì£¼ì†Œ ë˜ëŠ” ì¹´í…Œê³ ë¦¬ëŠ” í•„ìˆ˜ ì…ë ¥ì‚¬í•­ì…ë‹ˆë‹¤.", "error_type": "invalid_input"}
        
        # MCP ê·œì¹™ ê²€ì¦
        if not validate_mcp_call("query_any_collection", collection="schedules", address=address):
            return {"status": "error", "message": "âŒ MCP ê·œì¹™ ê²€ì¦ ì‹¤íŒ¨", "error_type": "mcp_validation_failed"}
        
        # ë¬¸ì„œ ê²€ìƒ‰
        found, doc_id, doc_data = _find_schedule_document(address)
        
        if not found:
            # íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬ì¸ ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€ ë³€ê²½
            if doc_data and doc_data.get("is_special_category"):
                return {
                    "status": "error",
                    "message": f"âŒ '{address}' ì¹´í…Œê³ ë¦¬ì˜ ìŠ¤ì¼€ì¤„ ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                    "error_type": "category_not_found",
                    "available_categories": list(SPECIAL_SCHEDULE_CATEGORIES)
                }
            else:
                return {
                    "status": "error",
                    "message": f"âŒ '{address}' ì£¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "error_type": "address_not_found",
                    "hint": f"íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬: {', '.join(SPECIAL_SCHEDULE_CATEGORIES)}"
                }
        
        # eventsJson íŒŒì‹±
        events_json_str = doc_data.get("eventsJson", "{}")
        try:
            events = json.loads(events_json_str)
        except json.JSONDecodeError:
            events = {}
        
        # ëª¨ë“  ì´ë²¤íŠ¸ë¥¼ ë‚ ì§œë³„ë¡œ ì •ë¦¬
        schedules = []
        for event_key, event_data in events.items():
            # ì´ë²¤íŠ¸ í‚¤ì—ì„œ ë‚ ì§œ ì¶”ì¶œ (YYYY-MM-DD_timestamp í˜•ì‹)
            date_part = event_key.split('_')[0] if '_' in event_key else "ì•Œ ìˆ˜ ì—†ëŠ” ë‚ ì§œ"
            
            schedule_info = {
                "address": address,
                "date": date_part,
                "memo": event_data.get("memo", ""),
                "status": event_data.get("status", "unknown"),
                "title": event_data.get("title", ""),
                "event_key": event_key
            }
            schedules.append(schedule_info)
        
        # ë‚ ì§œìˆœ ì •ë ¬
        schedules.sort(key=lambda x: x["date"])
        
        log_operation("list_schedules_by_address", "success", {"address": address, "count": len(schedules)})
        
        return {
            "status": "success",
            "message": f"âœ… '{address}'ì˜ ìŠ¤ì¼€ì¤„ {len(schedules)}ê°œë¥¼ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.",
            "data": {
                "address": address,
                "schedules": schedules,
                "count": len(schedules),
                "action": "listed_by_address"
            }
        }
        
    except Exception as e:
        error_msg = handle_mcp_error(e, f"ì£¼ì†Œë³„ ìŠ¤ì¼€ì¤„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ (address: {address})")
        logger.error(error_msg)
        return {"status": "error", "message": f"âŒ ìŠ¤ì¼€ì¤„ ì¡°íšŒ ì‹¤íŒ¨: {error_msg}", "error_type": "system_error"}

# ==============================================================================
# ğŸ”§ ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê¹…
# ==============================================================================

logger.info("ğŸ“… ìŠ¤ì¼€ì¤„ ê´€ë¦¬ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
logger.info(f"   - MCP ê·œì¹™: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if MCP_RULES_AVAILABLE else 'âš ï¸ í´ë°± ëª¨ë“œ'}")
logger.info(f"   - Firebase ë„êµ¬: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if FIREBASE_TOOLS_AVAILABLE else 'âš ï¸ í´ë°± ëª¨ë“œ'}")
logger.info(f"   - Firebase í´ë¼ì´ì–¸íŠ¸: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if FIREBASE_CLIENT_AVAILABLE else 'âš ï¸ í´ë°± ëª¨ë“œ'}")
logger.info("   - ì œê³µ ê¸°ëŠ¥: ìŠ¤ì¼€ì¤„ ë“±ë¡/ìˆ˜ì •/ì‚­ì œ/ë‚ ì§œë³„ì¡°íšŒ/ì£¼ì†Œë³„ì¡°íšŒ (5ê°œ ë„êµ¬)")
logger.info(f"   - íŠ¹ìˆ˜ ì¹´í…Œê³ ë¦¬: {', '.join(SPECIAL_SCHEDULE_CATEGORIES)}") 